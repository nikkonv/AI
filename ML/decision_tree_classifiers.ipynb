{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"decision_tree_classifiers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZW9lEYp0osT3","colab_type":"text"},"source":["# Árboles de decisión para clasificación\n","Uno de los algoritmos más populares, por su fácil entendimiento. Selecciona el mejor atributo a partir de una medida para generar un nodo de decisión, se usa una heurística para seleccionar el \"camino\" en cada nodo de desición. \n","\n","![texto alternativo](https://miro.medium.com/max/410/1*JAEY3KP7TU2Q6HN6LasMrw.png)\n","\n","Ventajas \n","* Fáciles de interpretar y visualizar, pueden capturar fácilmente patrones no lineales.\n","* Requiere menos preprocesamiento de datos por parte del usuario, por ejemplo, no es necsario normalizar las columnas.\n","* Se puede utilizar para la ingeniería de características, como la predicción de valores perdidos, adecuada para la selección de variables.\n","* El árbol de decisión no tiene suposiciones sobre la distribución debido a la naturaleza no paramétrica del algoritmo.\n","\n","Desventajas\n","* Datos sensibles al ruido, puede sobredimensionar los datos ruidosos.\n","* La pequeña variación en los datos puede dar lugar a un arbol de decisión diferente.\n","* Están sesgados con un conjunto de datos de desequilibrio, por lo que se recomienda equilibrar el conjunto de datos antes de crear el arbol de decisión. \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"MBDq0S0prapw","colab_type":"code","colab":{}},"source":["from sklearn import datasets\n","\n","data = datasets.load_breast_cancer()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZ-VyqNNrdDc","colab_type":"code","colab":{}},"source":["X = data.data\n","y = data.target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g5D81mjmrt7g","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","from sklearn.tree import DecisionTreeClassifier\n","\n","tree = DecisionTreeClassifier(criterion = 'entropy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJjXYZ0esbZe","colab_type":"code","colab":{}},"source":["tree.fit(X_train, y_train)\n","\n","y_pred = tree.predict(X_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXzmI8ENsrR3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"d468bf22-ec98-4a27-ee24-2b1cc0ee71fd","executionInfo":{"status":"ok","timestamp":1575677568473,"user_tz":180,"elapsed":1059,"user":{"displayName":"Nicolas Navarrete","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXaHuOisCUniMdotsmoSVH4oba_jwxWkOQPsh0zg=s64","userId":"16401348718469471538"}}},"source":["from sklearn.metrics import confusion_matrix\n","\n","matrix = confusion_matrix(y_test, y_pred)\n","matrix"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[37,  4],\n","       [ 3, 70]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"m7Ns-rOBs9F1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"341f0771-f4e9-44ed-c229-6e7f665c770f","executionInfo":{"status":"ok","timestamp":1575677657551,"user_tz":180,"elapsed":1017,"user":{"displayName":"Nicolas Navarrete","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBXaHuOisCUniMdotsmoSVH4oba_jwxWkOQPsh0zg=s64","userId":"16401348718469471538"}}},"source":["from sklearn.metrics import precision_score\n","from sklearn.metrics import f1_score\n","\n","print('precision: ', precision_score(y_test, y_pred))\n","print('f1: ', f1_score(y_test, y_pred))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["precision:  0.9459459459459459\n","f1:  0.9523809523809523\n"],"name":"stdout"}]}]}